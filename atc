https://atc24.usenix.hotcrp.com/paper/532

A:

The paper shows a toy example of using fewer time slots as a time optimization, and it says that the real data is intensive and smooth. Showing the data here would more strongly back up the decision to use fewer time slots. Along the same lines of time slots, it is mentioned that the goal is to solve the optimization problem in a few hours (10 hours in your network). However, after describing the time slots optimization, it mentions that it can be solved in 20 minutes. Since there appears to be a tradeoff between time and accuracy of the optimization problem, would it make sense to use more time and get higher accuracy? Also, I'm curious about how the goal of running in a few hours was decided.
	可以补充图来证明the real data is intensive and smooth（应该有现成的）
	288个时隙一天多还没跑出结果来，gap是怎么评估的？

At the beginning of section 5.3, it is mentioned that the local controller in each PoP runs algorithms and uploads results to the controller, as shown in Figure 6. Figure 6 doesn't contain information about the locations that any computations are being run.


When describing the congestion of the backbone network, it is mentioned that you verify the problem and find the results described (overflowing links), but information about what data was examined and how you made this observation is missing.
忽略骨干网容量约束或者说认为骨干网容量无穷大的条件下来做BGP流量调度，然后检查骨干网链路的利用率情况，统计利用率超限的链路比例。

All data in the paper appears to be from one week in May 2023. Do you have any other data or anything to show that this was a "typical" week in terms of things like percentage of performance-sensitive applications?
我们有更多的实际数据，它们的分布特征基本一致，我们可以在论文里show一下数据情况。论文中已经提到了。。。

Lastly, I think the eval would benefit from more of a deep-dive into the effect of each component. The component analysis for Forest Bitmap is present and looks good, but it would have been good to see the effect if you hadn't considered backbone limitations, or didn't maximally utilize bursting links.  ==》后面提供。冲顶阈值有实验数据

B:
Weaknesses:
Evaluation methodology
Incremental contribution
Generality
The paper is engaging and presents intriguing results; however, it lacks several essential attributes crucial for publication.

Evaluation methodology.

Most of the evaluation is conducted against benign baselines, such as BGP and Google RadixTree.
1.1	Since you have already compared against the state-of-the-art (Fig. 11), it would be expected that all other experiments (Figs. 12, 13, 14) yield similar comparisons. 我们是第一次做成本和性能的多目标优化，cascara
1.2	While comparisons against BGP are useful, they are less interesting, given that Cascara has already demonstrated similar results.  
1.3	 1.2 Google RadixTree is a 15-year-old longest-prefix-match implementation. It is recommended to consider more recent algorithms in this field, such as the popular highly optimized DPDK implementation.

Fig. 12 poses a challenge as the reader cannot ascertain whether a 2ms reduction in latency is significant or not. For instance, a 2ms reduction out of 10ms would be more noteworthy than a 2ms reduction out of 60ms.
===》之前考虑的是不泄露真实数据，34->36

The problem addressed in your paper is not novel within the community, as several works have already been published in this field. Consequently, the paper's primary contributions lie in providing new insights, such as taking into account link capacities and utilizing inter-PoP strategies, and presenting observations derived from real-world production systems. However, there is a sense that many of these insights and observations are obscured, consequently limiting the contribution and narrowing the applicability of your solution to a very specific use case. I recommend providing more detailed information about real-world production characteristics, akin to Fig. 5. (You may consider Fig. 4 in "Inside the Social Network's (Datacenter) Network, SIGCOMM'15" as an example).


